{"cells":[{"cell_type":"markdown","source":["# ðŸ“š Natural Language Processing: Spelling Correction\n","### BITS Pilani - NLP Applications Tutorial\n","This notebook provides hands-on implementation of spelling correction concepts including:\n","- Basic spell checking\n","- Edit distance calculation\n","- Noisy channel model\n","- Context-aware corrections\n","- Enhanced Error Types Handler\n","- Technical Terms Handler\n","- Evaluation Framework"],"metadata":{"id":"qvrLFEkPjKZ6"},"id":"qvrLFEkPjKZ6"},{"cell_type":"markdown","source":["## 1. Setup and Required Libraries\n","\n","First, let's install and import the required libraries:"],"metadata":{"id":"gMV3kVrpjZBc"},"id":"gMV3kVrpjZBc"},{"cell_type":"code","execution_count":1,"id":"922b92d5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"922b92d5","outputId":"d925e762-ab71-4ec9-851e-489d57267b6b","executionInfo":{"status":"ok","timestamp":1733558761892,"user_tz":-330,"elapsed":13956,"user":{"displayName":"Chetana Anoop Gavankar","userId":"16410822309710390011"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n","Setup completed!\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package words to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/words.zip.\n"]}],"source":["!pip install nltk\n","\n","import numpy as np\n","import pandas as pd\n","from collections import Counter\n","import re\n","from typing import List, Dict, Set, Tuple\n","import nltk\n","from nltk.corpus import words\n","nltk.download('words')\n","\n","print(\"Setup completed!\")\n","\n"]},{"cell_type":"markdown","source":["## 2. Basic Spell Checking Functions\n","\n","Let's implement the core functions needed for spell checking:"],"metadata":{"id":"BxUz0TrHjj8H"},"id":"BxUz0TrHjj8H"},{"cell_type":"code","source":["class SpellChecker:\n","    def __init__(self):\n","        # Initialize vocabulary using NLTK words\n","        self.vocabulary = set(words.words())\n","\n","    def is_word(self, word: str) -> bool:\n","        \"\"\"Check if a word exists in the vocabulary.\"\"\"\n","        return word.lower() in self.vocabulary\n","\n","    def edit_distance(self, s1: str, s2: str) -> int:\n","        \"\"\"Calculate Damerau-Levenshtein distance between two strings.\"\"\"\n","        len_s1, len_s2 = len(s1), len(s2)\n","        dp = [[0] * (len_s2 + 1) for _ in range(len_s1 + 1)]\n","\n","        # Initialize first row and column\n","        for i in range(len_s1 + 1):\n","            dp[i][0] = i\n","        for j in range(len_s2 + 1):\n","            dp[0][j] = j\n","\n","        for i in range(1, len_s1 + 1):\n","            for j in range(1, len_s2 + 1):\n","                cost = 0 if s1[i-1] == s2[j-1] else 1\n","                dp[i][j] = min(\n","                    dp[i-1][j] + 1,      # deletion\n","                    dp[i][j-1] + 1,      # insertion\n","                    dp[i-1][j-1] + cost  # substitution\n","                )\n","                # Handle transposition\n","                if (i > 1 and j > 1 and s1[i-1] == s2[j-2] and s1[i-2] == s2[j-1]):\n","                    dp[i][j] = min(dp[i][j], dp[i-2][j-2] + 1)\n","\n","        return dp[len_s1][len_s2]\n","\n","    def generate_candidates(self, word: str, max_distance: int = 2) -> List[str]:\n","        \"\"\"Generate possible corrections for a word.\"\"\"\n","        return [w for w in self.vocabulary\n","                if self.edit_distance(word.lower(), w.lower()) <= max_distance]\n","\n","# Create instance\n","spell_checker = SpellChecker()\n","print(\"Spell checker initialized!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"clEMpNAzjFsN","outputId":"420843f8-da6f-4092-8266-83a270e4b958","executionInfo":{"status":"ok","timestamp":1733562384512,"user_tz":-330,"elapsed":516,"user":{"displayName":"Chetana Anoop Gavankar","userId":"16410822309710390011"}}},"id":"clEMpNAzjFsN","execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Spell checker initialized!\n"]}]},{"cell_type":"markdown","source":["## 3. Testing Basic Spell Checking\n","\n","Let's test our spell checker with some examples:"],"metadata":{"id":"umBnsPL3jzhO"},"id":"umBnsPL3jzhO"},{"cell_type":"code","source":["test_words = [\"happyness\", \"langauge\", \"speling\", \"computr\"]\n","\n","for word in test_words:\n","    candidates = spell_checker.generate_candidates(word)\n","    print(f\"\\nMisspelled word: {word}\")\n","    print(f\"Suggested corrections: {', '.join(candidates[:5])}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4WexvcWRju89","outputId":"2f3da65b-7a11-4441-fad9-91e98dccb595","executionInfo":{"status":"ok","timestamp":1733562456803,"user_tz":-330,"elapsed":64741,"user":{"displayName":"Chetana Anoop Gavankar","userId":"16410822309710390011"}}},"id":"4WexvcWRju89","execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Misspelled word: happyness\n","Suggested corrections: happiless, yappiness, happiness, nappiness, sappiness\n","\n","Misspelled word: langauge\n","Suggested corrections: language, languaged, langrage, slanguage\n","\n","Misspelled word: speling\n","Suggested corrections: seeking, shelling, keeling, styling, smiling\n","\n","Misspelled word: computr\n","Suggested corrections: comport, compete, commuter, compeer, compote\n"]}]},{"cell_type":"markdown","source":["## 4. Implementing Noisy Channel Model\n","\n","Now let's implement the noisy channel model for better correction suggestions:"],"metadata":{"id":"FXqhLu5KkIx0"},"id":"FXqhLu5KkIx0"},{"cell_type":"code","source":["class NoiseChannelSpellChecker(SpellChecker):\n","    def __init__(self):\n","        super().__init__()\n","        # Add word frequency information\n","        self.word_freq = Counter()\n","\n","    def train(self, text: str):\n","        \"\"\"Train the model on a text corpus.\"\"\"\n","        words = re.findall(r'\\w+', text.lower())\n","        self.word_freq.update(words)\n","        self.total_words = sum(self.word_freq.values())\n","\n","    def P_word(self, word: str) -> float:\n","        \"\"\"Calculate prior probability of word.\"\"\"\n","        return (self.word_freq[word.lower()] + 1) / (self.total_words + len(self.vocabulary))\n","\n","    def P_error(self, error: str, word: str) -> float:\n","        \"\"\"Calculate error probability P(error|word).\"\"\"\n","        distance = self.edit_distance(error.lower(), word.lower())\n","        return np.exp(-distance)\n","\n","    def correct_word(self, error: str) -> str:\n","        \"\"\"Find most likely correction.\"\"\"\n","        if self.is_word(error):\n","            return error\n","\n","        candidates = self.generate_candidates(error)\n","        if not candidates:\n","            return error\n","\n","        # Find correction with highest probability\n","        return max(candidates,\n","                  key=lambda w: self.P_error(error, w) * self.P_word(w))\n","\n","# Create and train noisy channel model\n","noise_checker = NoiseChannelSpellChecker()\n","\n","# Sample training text\n","training_text = \"\"\"\n","Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence\n","concerned with the interactions between computers and human language.\n","\"\"\"\n","\n","noise_checker.train(training_text)\n","print(\"Noisy channel model trained!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YkAMRORJkLL1","outputId":"84aaeba0-dd2c-4aa6-b11d-5f77dac54b8b","executionInfo":{"status":"ok","timestamp":1733562483663,"user_tz":-330,"elapsed":463,"user":{"displayName":"Chetana Anoop Gavankar","userId":"16410822309710390011"}}},"id":"YkAMRORJkLL1","execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Noisy channel model trained!\n"]}]},{"cell_type":"markdown","source":["## 5. Evaluation and Testing\n","\n","Let's test our noisy channel spell checker:"],"metadata":{"id":"Ja6Ww9QQkas1"},"id":"Ja6Ww9QQkas1"},{"cell_type":"code","source":["test_cases = [\n","    \"naturel\",\n","    \"languge\",\n","    \"computr\",\n","    \"artifical\"\n","]\n","\n","print(\"Spell Correction Results:\")\n","print(\"-\" * 40)\n","for word in test_cases:\n","    correction = noise_checker.correct_word(word)\n","    print(f\"Original: {word:15} â†’ Correction: {correction}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hao5YoApkfrd","outputId":"2347f64a-1d1e-43f0-ce46-f9a3c3e6a711","executionInfo":{"status":"ok","timestamp":1733558903090,"user_tz":-330,"elapsed":64195,"user":{"displayName":"Chetana Anoop Gavankar","userId":"16410822309710390011"}}},"id":"Hao5YoApkfrd","execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Spell Correction Results:\n","----------------------------------------\n","Original: naturel         â†’ Correction: natural\n","Original: languge         â†’ Correction: language\n","Original: computr         â†’ Correction: computer\n","Original: artifical       â†’ Correction: artificial\n"]}]},{"cell_type":"markdown","source":["# 6. Context-Aware Spell Checker"],"metadata":{"id":"vHelsaMEk7hg"},"id":"vHelsaMEk7hg"},{"cell_type":"code","source":["class ContextAwareSpellChecker(NoiseChannelSpellChecker):\n","    def __init__(self):\n","        super().__init__()\n","        self.bigram_counts = Counter()\n","\n","    def train(self, text: str):\n","        \"\"\"Train both word frequencies and bigram counts.\"\"\"\n","        super().train(text)\n","        # Create bigrams from text\n","        words = re.findall(r'\\w+', text.lower())\n","        self.bigrams = list(zip(words[:-1], words[1:]))\n","        self.bigram_counts.update(self.bigrams)\n","\n","    def P_context(self, prev_word: str, word: str, next_word: str) -> float:\n","        \"\"\"Calculate probability based on surrounding context.\"\"\"\n","        prev_bigram = (prev_word.lower(), word.lower())\n","        next_bigram = (word.lower(), next_word.lower())\n","\n","        # Combine previous and next bigram probabilities\n","        prev_count = self.bigram_counts[prev_bigram] + 1\n","        next_count = self.bigram_counts[next_bigram] + 1\n","        total_bigrams = sum(self.bigram_counts.values()) + len(self.vocabulary)**2\n","\n","        return (prev_count * next_count) / (total_bigrams * total_bigrams)\n","\n","    def correct_text(self, text: str) -> str:\n","        \"\"\"Correct entire text considering context.\"\"\"\n","        words = re.findall(r'\\w+', text)\n","        corrected_words = []\n","\n","        for i in range(len(words)):\n","            prev_word = words[i-1] if i > 0 else \"<START>\"\n","            next_word = words[i+1] if i < len(words)-1 else \"<END>\"\n","\n","            if not self.is_word(words[i]):\n","                candidates = self.generate_candidates(words[i])\n","                if candidates:\n","                    # Consider both error probability and context\n","                    best_word = max(candidates,\n","                                  key=lambda w: (self.P_error(words[i], w) *\n","                                               self.P_word(w) *\n","                                               self.P_context(prev_word, w, next_word)))\n","                    corrected_words.append(best_word)\n","                else:\n","                    corrected_words.append(words[i])\n","            else:\n","                corrected_words.append(words[i])\n","\n","        return ' '.join(corrected_words)"],"metadata":{"id":"iG6iTxt7lHcP","executionInfo":{"status":"ok","timestamp":1733562529346,"user_tz":-330,"elapsed":446,"user":{"displayName":"Chetana Anoop Gavankar","userId":"16410822309710390011"}}},"id":"iG6iTxt7lHcP","execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["# 7. Test context-aware spell checker"],"metadata":{"id":"ussQgxN8lXaV"},"id":"ussQgxN8lXaV"},{"cell_type":"code","source":["context_checker = ContextAwareSpellChecker()\n","context_checker.train(\"\"\"\n","    The quick brown fox jumps over the lazy dog.\n","    Natural language processing helps computers understand human language.\n","    Machine learning models can process large amounts of text data.\n","\"\"\")\n","\n","test_text = \"The quik brown fox jumps ovr the lasy dog\"\n","corrected_text = context_checker.correct_text(test_text)\n","print(f\"Original: {test_text}\")\n","print(f\"Corrected: {corrected_text}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vesDhIEOlUGG","outputId":"1f1bf358-f7a5-48dc-e40d-ae568e1073a6","executionInfo":{"status":"ok","timestamp":1733558936321,"user_tz":-330,"elapsed":33247,"user":{"displayName":"Chetana Anoop Gavankar","userId":"16410822309710390011"}}},"id":"vesDhIEOlUGG","execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Original: The quik brown fox jumps ovr the lasy dog\n","Corrected: The quick brown fox mumps over the lazy dog\n"]}]},{"cell_type":"markdown","source":["# 8. Enhanced Error Types Handler"],"metadata":{"id":"xXMJG7Rfljqt"},"id":"xXMJG7Rfljqt"},{"cell_type":"code","source":["class EnhancedSpellChecker(ContextAwareSpellChecker):\n","    def generate_candidates_enhanced(self, word: str) -> Set[str]:\n","        \"\"\"Generate candidates with various error types.\"\"\"\n","        candidates = set()\n","        letters = 'abcdefghijklmnopqrstuvwxyz'\n","        word = word.lower()\n","\n","        # Original edit distance candidates\n","        candidates.update(self.generate_candidates(word))\n","\n","        # 1. Transpositions\n","        for i in range(len(word)-1):\n","            transposed = word[:i] + word[i+1] + word[i] + word[i+2:]\n","            if self.is_word(transposed):\n","                candidates.add(transposed)\n","\n","        # 2. Phonetic similarities\n","        phonetic_rules = {\n","            'ph': 'f', 'ght': 't', 'kn': 'n', 'wh': 'w',\n","            'ing': 'in', 'ed': 't', 'tion': 'shun'\n","        }\n","\n","        for pattern, replacement in phonetic_rules.items():\n","            if pattern in word:\n","                phonetic = word.replace(pattern, replacement)\n","                if self.is_word(phonetic):\n","                    candidates.add(phonetic)\n","\n","        # 3. Common typos\n","        keyboard_neighbors = {\n","            'a': 'qwsz', 'b': 'vghn', 'c': 'xdfv', 'd': 'sfxc',\n","            'e': 'wrsdf', 'f': 'dcvgr', 'g': 'fvbht', 'h': 'gbynj',\n","            'i': 'ujko', 'j': 'hunkm', 'k': 'jmlo', 'l': 'kop',\n","            'm': 'njk', 'n': 'bhjm', 'o': 'iklp', 'p': 'ol',\n","            'q': 'wa', 'r': 'edft', 's': 'awdxz', 't': 'rfgy',\n","            'u': 'yhji', 'v': 'cfgb', 'w': 'qase', 'x': 'zsdc',\n","            'y': 'tghu', 'z': 'asx'\n","        }\n","\n","        for i, char in enumerate(word):\n","            if char in keyboard_neighbors:\n","                for neighbor in keyboard_neighbors[char]:\n","                    typo = word[:i] + neighbor + word[i+1:]\n","                    if self.is_word(typo):\n","                        candidates.add(typo)\n","\n","        return candidates\n","\n","    def correct_word(self, error: str) -> str:\n","        \"\"\"Find most likely correction using enhanced candidate generation.\"\"\"\n","        if self.is_word(error):\n","            return error\n","\n","        candidates = self.generate_candidates_enhanced(error)\n","        if not candidates:\n","            return error\n","\n","        return max(candidates,\n","                  key=lambda w: self.P_error(error, w) * self.P_word(w))"],"metadata":{"id":"_9eM5FMNluNs","executionInfo":{"status":"ok","timestamp":1733558936321,"user_tz":-330,"elapsed":5,"user":{"displayName":"Chetana Anoop Gavankar","userId":"16410822309710390011"}}},"id":"_9eM5FMNluNs","execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["# 9. Test enhanced spell checker"],"metadata":{"id":"nPGjO9zil6mG"},"id":"nPGjO9zil6mG"},{"cell_type":"code","source":["enhanced_checker = EnhancedSpellChecker()\n","enhanced_checker.train(\"\"\"\n","    The quick brown fox jumps over the lazy dog.\n","    Physics and chemistry are important sciences.\n","    Knowledge is power in the modern world.\n","\"\"\")\n","\n","test_words = [\"phisics\", \"kemistry\", \"nowledge\", \"recieved\"]\n","for word in test_words:\n","    correction = enhanced_checker.correct_word(word)\n","    print(f\"Original: {word:10} â†’ Correction: {correction}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oN8Z097al6BV","outputId":"5c5d80f0-5ee8-4987-c904-d79a50033c46","executionInfo":{"status":"ok","timestamp":1733559001178,"user_tz":-330,"elapsed":64861,"user":{"displayName":"Chetana Anoop Gavankar","userId":"16410822309710390011"}}},"id":"oN8Z097al6BV","execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Original: phisics    â†’ Correction: physics\n","Original: kemistry   â†’ Correction: chemistry\n","Original: nowledge   â†’ Correction: knowledge\n","Original: recieved   â†’ Correction: received\n"]}]},{"cell_type":"markdown","source":[" # 10. Technical Terms Handler"],"metadata":{"id":"vJ7rkR27mUl9"},"id":"vJ7rkR27mUl9"},{"cell_type":"code","source":["class TechnicalSpellChecker(EnhancedSpellChecker):\n","    def __init__(self):\n","        super().__init__()\n","        self.technical_terms = set()\n","        self.proper_nouns = set()\n","\n","    def add_technical_vocabulary(self, domain: str, terms: List[str]):\n","        \"\"\"Add domain-specific technical terms.\"\"\"\n","        self.technical_terms.update(term.lower() for term in terms)\n","\n","    def add_proper_nouns(self, nouns: List[str]):\n","        \"\"\"Add proper nouns to vocabulary.\"\"\"\n","        self.proper_nouns.update(noun.lower() for noun in nouns)\n","\n","    def is_word(self, word: str) -> bool:\n","        \"\"\"Check if word exists in any vocabulary.\"\"\"\n","        word = word.lower()\n","        return (super().is_word(word) or\n","                word in self.technical_terms or\n","                word in self.proper_nouns)\n","\n","    def suggest_technical_terms(self, word: str) -> List[str]:\n","        \"\"\"Suggest corrections from technical vocabulary.\"\"\"\n","        return [term for term in self.technical_terms\n","                if self.edit_distance(word.lower(), term) <= 2]"],"metadata":{"id":"dnmqJRpXmXCV","executionInfo":{"status":"ok","timestamp":1733559001179,"user_tz":-330,"elapsed":7,"user":{"displayName":"Chetana Anoop Gavankar","userId":"16410822309710390011"}}},"id":"dnmqJRpXmXCV","execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["# 11. Test technical spell checker"],"metadata":{"id":"AB5mGbNmm2ws"},"id":"AB5mGbNmm2ws"},{"cell_type":"code","source":["tech_checker = TechnicalSpellChecker()\n","\n","# First train with some base text\n","tech_checker.train(\"\"\"\n","    Programming languages are essential tools for software development.\n","    Machine learning models help in processing data efficiently.\n","    Cloud computing enables scalable solutions for businesses.\n","    Google Cloud is a popular cloud service provider.\n","    sklearn and tensorflow are popular machine learning library.\n","\"\"\")\n","\n","# Add technical terms\n","tech_terms = [\n","    \"Python\", \"JavaScript\", \"React\", \"TensorFlow\",\n","    \"NumPy\", \"pandas\", \"sklearn\", \"PyTorch\"\n","]\n","tech_checker.add_technical_vocabulary(\"programming\", tech_terms)\n","\n","# Add proper nouns\n","proper_nouns = [\"Google\", \"Microsoft\", \"Amazon\", \"Facebook\"]\n","tech_checker.add_proper_nouns(proper_nouns)\n","\n","# Test the spell checker\n","test_technical = [\"pythn\", \"tensorflow\", \"googel\", \"sklaern\"]\n","for word in test_technical:\n","    correction = tech_checker.correct_word(word)\n","    print(f\"Technical term: {word:10} â†’ Correction: {correction}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pK2P8pZLm9P5","outputId":"4bd7ad72-5419-46bb-a8e4-617c26a34792","executionInfo":{"status":"ok","timestamp":1733559039545,"user_tz":-330,"elapsed":38372,"user":{"displayName":"Chetana Anoop Gavankar","userId":"16410822309710390011"}}},"id":"pK2P8pZLm9P5","execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Technical term: pythn      â†’ Correction: python\n","Technical term: tensorflow â†’ Correction: tensorflow\n","Technical term: googel     â†’ Correction: google\n","Technical term: sklaern    â†’ Correction: sklearn\n"]}]},{"cell_type":"markdown","source":["# 12. Evaluation Framework"],"metadata":{"id":"x-IT1kKUnDtN"},"id":"x-IT1kKUnDtN"},{"cell_type":"code","source":["class SpellCheckerEvaluator:\n","    def __init__(self, spell_checker):\n","        self.spell_checker = spell_checker\n","\n","    def evaluate(self, test_cases: List[Tuple[str, str]]) -> Dict[str, float]:\n","        \"\"\"\n","        Evaluate spell checker performance.\n","        test_cases: List of (error, correct) word pairs\n","        \"\"\"\n","        total = len(test_cases)\n","        correct = 0\n","        false_positives = 0\n","        false_negatives = 0\n","\n","        for error, truth in test_cases:\n","            prediction = self.spell_checker.correct_word(error)\n","\n","            if prediction == truth:\n","                correct += 1\n","            else:\n","                if self.spell_checker.is_word(error) and error != truth:\n","                    false_negatives += 1\n","                if prediction != truth:\n","                    false_positives += 1\n","\n","        precision = correct / (correct + false_positives) if (correct + false_positives) > 0 else 0\n","        recall = correct / (correct + false_negatives) if (correct + false_negatives) > 0 else 0\n","        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n","\n","        return {\n","            \"accuracy\": correct / total,\n","            \"precision\": precision,\n","            \"recall\": recall,\n","            \"f1_score\": f1\n","        }\n"],"metadata":{"id":"HKdiRLKMnJvu","executionInfo":{"status":"ok","timestamp":1733559039549,"user_tz":-330,"elapsed":87,"user":{"displayName":"Chetana Anoop Gavankar","userId":"16410822309710390011"}}},"id":"HKdiRLKMnJvu","execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["# 13. Test evaluation framework"],"metadata":{"id":"JUnfOysMnXn2"},"id":"JUnfOysMnXn2"},{"cell_type":"code","source":["test_cases = [\n","    (\"happyness\", \"happiness\"),\n","    (\"recieve\", \"receive\"),\n","    (\"independant\", \"independent\"),\n","    (\"occured\", \"occurred\"),\n","    (\"definately\", \"definitely\")\n","]\n","\n","evaluator = SpellCheckerEvaluator(enhanced_checker)\n","metrics = evaluator.evaluate(test_cases)\n","\n","print(\"\\nEvaluation Results:\")\n","for metric, value in metrics.items():\n","    print(f\"{metric}: {value:.3f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v6TzE3IUncvd","outputId":"924a8628-1628-40f1-db3a-1993bfe1c1be","executionInfo":{"status":"ok","timestamp":1733559133655,"user_tz":-330,"elapsed":94186,"user":{"displayName":"Chetana Anoop Gavankar","userId":"16410822309710390011"}}},"id":"v6TzE3IUncvd","execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Evaluation Results:\n","accuracy: 0.600\n","precision: 0.600\n","recall: 1.000\n","f1_score: 0.750\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}